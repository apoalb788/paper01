{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "556b81cf",
   "metadata": {},
   "source": [
    "# Standard Reservoir Computer (paper version)\n",
    "\n",
    "### hyperparameters optimization\n",
    "\n",
    "### ( datasets by $\\rho \\in A =$ list of values  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae665baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import math     as math\n",
    "import numpy    as np\n",
    "import networkx as nx\n",
    "import random   as random\n",
    "import pandas   as pd\n",
    "import time     as time\n",
    "\n",
    "#######################################################################\n",
    "# E N V I R O N M E N T   S E T   U P\n",
    "#######################################################################\n",
    "#---------------------------------------------------------------------#\n",
    "# To compute elapsed time\n",
    "#---------------------------------------------------------------------#\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5bb9f7",
   "metadata": {},
   "source": [
    "## variables description\n",
    "    D       :(int  ) Input data dimension      \n",
    "    N       :(int  ) Reservoir dimension (degrees of freedome of the reservoir)       \n",
    "    rhoSR   :(float) Spectral Radius of A      \n",
    "    rhoA    :(float) Density of A              \n",
    "    alpha   :(float) Leak (or leakage) rate in (0,1]                 \n",
    "    sigma   :(float) Strength of input signal            \n",
    "    sigmab  :(float) Strength of input bias               \n",
    "    beta    :(float) Tichonov-Miller regularization parameter\n",
    "    \n",
    "    washout :(int)   During training, skipped transitory timesteps in W_out calculation\n",
    "    spinup  :(int)   Time (n. of timesteps) it takes for a trained RC to converge from its initial condition\n",
    "                     onto the synchronization manifold to which it is driven by the input data\n",
    "    normtime:(int)   Range to skip some QR factorisations and speed up the calculations  \n",
    "            \n",
    "    r       :(float) Reservoir state\n",
    "    W_in    :(float) Input matrix              \n",
    "    A       :(float) Reservoir ajacency matrix \n",
    "    b       :(float) bias vector               \n",
    "    W_out   :(float) Output matrix  \n",
    "    endtr_r :(float) Last reservoir state in training\n",
    "    \n",
    "    R       :(float) Matrix containing r(t) for all t in training dataset\n",
    "    U       :(float) Matrix containing u(t) for all t in training dataset\n",
    "    u       :(float) Time series at time t\n",
    "    v       :(float) Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129942da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReservoirComputer class declaration\n",
    "class ReservoirComputer:\n",
    "    def __init__(self, D, N, rhoSR, rhoA, alpha, sigma, sigmab, beta):\n",
    "        self.r      = np.zeros(N)\n",
    "        self.W_in   = get_random_matrix(N, D, xa=-sigma, xb=sigma, nonzero=False)\n",
    "        self.A      = generate_adjacency_matrix(N, rhoSR, rhoA)\n",
    "        self.b      = sigmab * np.ones(N)\n",
    "        self.W_out  = np.zeros((D,N))\n",
    "        self.endtr_r= np.zeros(N)\n",
    "\n",
    "    def rc_update_rule(self, y):\n",
    "        # driven     mode: y = u(t)         ;r(t+1) = F^d_r (r(t),y)\n",
    "        # autonomous mode: y = W_out . r(t) ;r(t+1) = F^a_r (r(t),y)\n",
    "        g      = np.dot(self.A, self.r) + np.dot(self.W_in, y) + self.b\n",
    "        self.r = alpha * np.tanh(g) + (1 - alpha) * self.r\n",
    "\n",
    "    def update_v(self):\n",
    "        return np.dot(self.W_out, self.r)\n",
    "\n",
    "    def train(self, U, washout):\n",
    "        steps = U.shape[0]\n",
    "        R     = np.zeros((N, steps))\n",
    "        for i in range(steps):\n",
    "            R[:, i] = self.r\n",
    "            u       = U[i]\n",
    "            self.rc_update_rule(u)\n",
    "        self.W_out = linear_regression(R[:,washout:], U[washout:], beta)\n",
    "        self.endtr_r = self.r # save last training r state\n",
    "\n",
    "    def spinup(self, U, steps):\n",
    "        self.r = self.endtr_r # reset reservoir state\n",
    "        if steps > 0:\n",
    "            for i in range(steps):\n",
    "                u = U[i]\n",
    "                self.rc_update_rule(u) # driven mode\n",
    "    \n",
    "    def predict(self, steps):\n",
    "        prediction = np.zeros((steps, D))\n",
    "        for i in range(steps):\n",
    "            v             = self.update_v()\n",
    "            prediction[i] = v\n",
    "            self.rc_update_rule(v)\n",
    "        return prediction\n",
    "\n",
    "    def rc_lyapunov_exponents(self, steps, dt, normtime):\n",
    "        save_r = self.r # save r state\n",
    "        self.r = self.endtr_r # reset r state\n",
    "        lyap   = np.zeros((N,steps))\n",
    "        M      = np.eye(N)\n",
    "        W      = self.A + np.dot(self.W_in,self.W_out)\n",
    "        j      = -1\n",
    "        for i in range(steps):\n",
    "            v     = self.update_v()\n",
    "            self.rc_update_rule(v) # update r\n",
    "            #\n",
    "            g     = np.dot(W, self.r) + self.b\n",
    "            DF    = alpha * np.dot(np.diag(1 - np.tanh(g)**2),W) \\\n",
    "                    + (1 - alpha) * np.eye(N)\n",
    "            Mn    = np.dot(DF,M)\n",
    "            if (i % normtime == 0):\n",
    "                Q,Rii = np.linalg.qr(Mn)\n",
    "                j     += 1\n",
    "                lyap[:,j] = np.log(abs(np.diag(Rii)))\n",
    "                M = Q\n",
    "        L = np.sum(lyap,1) / ((j+1)*dt)    \n",
    "        self.r = save_r # retrieve saved r_state\n",
    "        return L\n",
    "\n",
    "    def rc_conditional_lyapunov_exponents(self, U, dt, normtime):\n",
    "        save_r = self.r # save r state\n",
    "        self.r = np.zeros(N) # reset r state\n",
    "        steps  = U.shape[0]\n",
    "        lyap   = np.zeros((N,steps))\n",
    "        M      = np.eye(N)\n",
    "        j      = -1\n",
    "        for i in range(steps):\n",
    "            u       = U[i]\n",
    "            self.rc_update_rule(u) # update r\n",
    "            #\n",
    "            g  = np.dot(self.A, self.r) + np.dot(self.W_in, u) + self.b\n",
    "            DF = alpha * np.dot(np.diag(1 - np.tanh(g)**2),self.A) \\\n",
    "                 + (1 - alpha) * np.eye(N)\n",
    "            Mn = np.dot(DF,M)\n",
    "            if (i % normtime == 0):\n",
    "                Q,Rii = np.linalg.qr(Mn)\n",
    "                j     += 1\n",
    "                lyap[:,j] = np.log(abs(np.diag(Rii)))\n",
    "                M = Q\n",
    "        CL = np.sum(lyap,1) / ((j+1)*dt)\n",
    "        self.r = save_r # retrieve saved r_state\n",
    "        return CL\n",
    "    \n",
    "# Helper functions\n",
    "def generate_adjacency_matrix(N, rhoSR, rhoA):\n",
    "    # Erdos-Reyni network\n",
    "    graph = nx.gnp_random_graph(N, rhoA)\n",
    "    adj   = nx.to_numpy_array(graph)\n",
    "    # Ensure random_array is of the same shape as the graph adjacency matrix\n",
    "    random_array = get_random_matrix(N, N, xa =-0.5, xb=0.5, nonzero=True)\n",
    "    # Multiply graph adjacency matrix with random values\n",
    "    rescaled     = adj * random_array\n",
    "    return scale_matrix(rescaled, rhoSR)\n",
    "\n",
    "def get_random_matrix(nrow, ncol, xa, xb, nonzero):\n",
    "    B = np.zeros((nrow,ncol))\n",
    "    for i in range(nrow):\n",
    "        for j in range(ncol):\n",
    "            if nonzero:\n",
    "                while B[i,j] == 0:\n",
    "                    B[i,j] = xa + (xb - xa) * np.random.rand()\n",
    "            else:\n",
    "                B[i,j] = xa + (xb - xa) * np.random.rand()\n",
    "    return B\n",
    "\n",
    "def scale_matrix(A, rhoSR):\n",
    "    eigenvalues = np.linalg.eigvals(A)    # compute eigenvlaues\n",
    "    sr = np.max(np.absolute(eigenvalues)) # compute spectral radius of A\n",
    "    if sr > 0:\n",
    "        A = A * rhoSR / sr                # rescaling matrix if A non zero\n",
    "    return A\n",
    "\n",
    "def linear_regression(R, U, beta=.0001): \n",
    "    Rt = np.transpose(R)\n",
    "    inverse_part = np.linalg.inv(np.dot(R, Rt) + beta * np.identity(R.shape[0]))\n",
    "    return np.dot(np.dot(U.T, Rt), inverse_part)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f1b2277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# O P T I M I Z A T I O N   L O S S   F U N C T I O N \n",
    "#######################################################################\n",
    "# spinup_list = list of spinups values for forecasting \n",
    "def loss_macro(RC,test_data,spinup_list,forecast_steps):\n",
    "    loss_value = 0.\n",
    "    for i in range(len(spinup_list)):\n",
    "        spinup_steps = spinup_list[i]\n",
    "        RC.spinup(test_data, spinup_steps)\n",
    "        #\n",
    "        pred_data = RC.predict(forecast_steps)\n",
    "        #\n",
    "        for j in range(forecast_steps):\n",
    "            loss_value += np.linalg.norm(test_data[spinup_steps+j] - pred_data[j])**2 \\\n",
    "                        * np.exp(- (j+1) / (forecast_steps) )\n",
    "    return loss_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42a8094c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HP list length = 36\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "# H Y P E R P A R A M E T E R S   L I S T \n",
    "#######################################################################\n",
    "N_list      = [400]\n",
    "rhoSR_list  = [0.2, 0.5, 0.8]\n",
    "rhoA_list   = [0.02]\n",
    "alpha_list  = [0.4, 0.6, 0.8]\n",
    "sigma_list  = [0.084]\n",
    "sigmab_list = [1.1, 1.3, 1.5, 1.7]\n",
    "beta_list   = [8.5e-8]\n",
    "\n",
    "cart_prod = [(a,b,c,d,e,f,g)\n",
    "             for a in N_list       \n",
    "             for b in rhoSR_list   \n",
    "             for c in rhoA_list    \n",
    "             for d in alpha_list   \n",
    "             for e in sigma_list   \n",
    "             for f in sigmab_list  \n",
    "             for g in beta_list   ]\n",
    "\n",
    "len_vec = len(cart_prod)\n",
    "vec_loss_macro = np.zeros(len_vec)\n",
    "\n",
    "print(\"HP list length =\",len_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae59a5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "# L I S T   O F   R H O   V A L U E S\n",
    "#######################################################################\n",
    "rho_list  = np.arange(0, 331, 1)\n",
    "\n",
    "rho_list  = np.append(rho_list, np.array([13.926667, 23.9, 24.058, 470./19., 30.485]))\n",
    "rho_list  = np.append(rho_list, np.array([99.524, 100.795]))\n",
    "rho_list  = np.append(rho_list, np.array([148.4, 166.07, 214.364, 233.5]))\n",
    "\n",
    "rho_list  = np.sort(rho_list)\n",
    "\n",
    "len_rho_list = len(rho_list)\n",
    "\n",
    "print(len_rho_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b113a7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====     0) : Lorenz rho =   0.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     1.5675209290842415e-06\n",
      "=====     1) : Lorenz rho =   1.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.8\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     0.0920261978887018\n",
      "=====     2) : Lorenz rho =   2.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.5\n",
      "            beta     8.5e-08\n",
      "            loss     2.6515264930553153\n",
      "=====     3) : Lorenz rho =   3.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     0.13184889729647578\n",
      "=====     4) : Lorenz rho =   4.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.8\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     7.907393155029841\n",
      "=====     5) : Lorenz rho =   5.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     4.179672500954224\n",
      "=====     6) : Lorenz rho =   6.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.8\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     1.0598785840326541\n",
      "=====     7) : Lorenz rho =   7.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     4.459749383179981\n",
      "=====     8) : Lorenz rho =   8.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     17.211346263042355\n",
      "=====     9) : Lorenz rho =   9.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     9.041254128951234\n",
      "=====    10) : Lorenz rho =  10.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.8\n",
      "            sigma    0.084\n",
      "            sigmab   1.5\n",
      "            beta     8.5e-08\n",
      "            loss     8.699633419891601\n",
      "=====    11) : Lorenz rho =  11.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.8\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     5.08198183578361\n",
      "=====    12) : Lorenz rho =  12.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     20.767422443674995\n",
      "=====    13) : Lorenz rho =  13.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     8.313208179807475\n",
      "=====    14) : Lorenz rho =  13.927\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     2.5422632416851476\n",
      "=====    15) : Lorenz rho =  14.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     8.790462351368834\n",
      "=====    16) : Lorenz rho =  15.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.8\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     19.226236490125423\n",
      "=====    17) : Lorenz rho =  16.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     12.208984883294688\n",
      "=====    18) : Lorenz rho =  17.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     15.791236717380222\n",
      "=====    19) : Lorenz rho =  18.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     7.749270690464778\n",
      "=====    20) : Lorenz rho =  19.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     11.068691993125343\n",
      "=====    21) : Lorenz rho =  20.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     12.251302656021224\n",
      "=====    22) : Lorenz rho =  21.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     5.699483359096577\n",
      "=====    23) : Lorenz rho =  22.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.8\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     22.609229864989295\n",
      "=====    24) : Lorenz rho =  23.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     13.946332685715799\n",
      "=====    25) : Lorenz rho =  23.900\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.8\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     33.20354679047724\n",
      "=====    26) : Lorenz rho =  24.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     41.96572591795834\n",
      "=====    27) : Lorenz rho =  24.058\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     100.69312948071351\n",
      "=====    28) : Lorenz rho =  24.737\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     620970.7700739965\n",
      "=====    29) : Lorenz rho =  25.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     328211.2378123621\n",
      "=====    30) : Lorenz rho =  26.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     189721.1746548648\n",
      "=====    31) : Lorenz rho =  27.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     225537.67851895615\n",
      "=====    32) : Lorenz rho =  28.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     323638.36032583425\n",
      "=====    33) : Lorenz rho =  29.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     148528.06078181532\n",
      "=====    34) : Lorenz rho =  30.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.5\n",
      "            beta     8.5e-08\n",
      "            loss     422492.51097223646\n",
      "=====    35) : Lorenz rho =  30.485\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     654372.755277255\n",
      "=====    36) : Lorenz rho =  31.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     683892.5396878707\n",
      "=====    37) : Lorenz rho =  32.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.8\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     618545.4267566354\n",
      "=====    38) : Lorenz rho =  33.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     813212.7641368218\n",
      "=====    39) : Lorenz rho =  34.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     782365.7162408137\n",
      "=====    40) : Lorenz rho =  35.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.5\n",
      "            beta     8.5e-08\n",
      "            loss     627022.5531243257\n",
      "=====    41) : Lorenz rho =  36.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     1099670.8456254585\n",
      "=====    42) : Lorenz rho =  37.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.8\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     1753686.6693003585\n",
      "=====    43) : Lorenz rho =  38.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.5\n",
      "            beta     8.5e-08\n",
      "            loss     965728.6971085577\n",
      "=====    44) : Lorenz rho =  39.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.5\n",
      "            beta     8.5e-08\n",
      "            loss     823776.1111662003\n",
      "=====    45) : Lorenz rho =  40.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.5\n",
      "            beta     8.5e-08\n",
      "            loss     1602241.339061794\n",
      "=====    46) : Lorenz rho =  41.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     902200.9013605498\n",
      "=====    47) : Lorenz rho =  42.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     2006833.3713705926\n",
      "=====    48) : Lorenz rho =  43.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     2467152.9035891355\n",
      "=====    49) : Lorenz rho =  44.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     1963525.4627776237\n",
      "=====    50) : Lorenz rho =  45.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.8\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     2025942.8242721152\n",
      "=====    51) : Lorenz rho =  46.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     2316643.1271076575\n",
      "=====    52) : Lorenz rho =  47.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.8\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     2883662.466181347\n",
      "=====    53) : Lorenz rho =  48.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.5\n",
      "            beta     8.5e-08\n",
      "            loss     2739686.8276393004\n",
      "=====    54) : Lorenz rho =  49.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.5\n",
      "            beta     8.5e-08\n",
      "            loss     1392443.0260797595\n",
      "=====    55) : Lorenz rho =  50.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     2604660.6413016184\n",
      "=====    56) : Lorenz rho =  51.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.5\n",
      "            beta     8.5e-08\n",
      "            loss     4284735.291566194\n",
      "=====    57) : Lorenz rho =  52.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     4709539.613150235\n",
      "=====    58) : Lorenz rho =  53.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     5116021.270416162\n",
      "=====    59) : Lorenz rho =  54.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     2956232.3471748624\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "# O P T I M I Z A T I O N   L O O P \n",
    "#######################################################################\n",
    "rnd_seed = 167\n",
    "nome_file = 'df_RC400_seed' + str(rnd_seed) + '_HP_parte01'\n",
    "s_from = 0\n",
    "s_to   = 60\n",
    "# store parameters and RC hyperparameters\n",
    "RC_HP   = np.zeros((s_to - s_from, 11)) #np.zeros((len_rho_list, 11))\n",
    "\n",
    "cnt = -1\n",
    "for s in range(s_from, s_to): #range(len_rho_list):\n",
    "    rho_Lorenz  = rho_list[s]\n",
    "    # read dataset\n",
    "    str_rho_Lorenz = (f'{rho_Lorenz:07.3f}').replace(\".\", \"_\")\n",
    "    print(\"===== \",f'{s:>4d}) : Lorenz rho = {rho_Lorenz:>7.3f}')\n",
    "    X = np.loadtxt('dataset/Lorenz_Dataset_'+str(str_rho_Lorenz)+'.csv',delimiter=\";\")\n",
    "    n_timesteps = len(X)\n",
    "    #print(n_timesteps)\n",
    "    \n",
    "    # splitting in training and test dataset\n",
    "    data_length          = len(X) \n",
    "    training_percentage  = .8\n",
    "    training_data_length = round(training_percentage * data_length) \n",
    "    #print(\"data_length          =\",data_length)\n",
    "    #print(\"training_data_length =\",training_data_length)\n",
    "    training_data = np.array(X[:training_data_length])\n",
    "    test_data     = np.array(X[training_data_length:])\n",
    "    \n",
    "    # Setting random seed for repeteability\n",
    "    \n",
    "    np.random.seed(rnd_seed)\n",
    "    random.seed(rnd_seed)\n",
    "    \n",
    "    # Set random forecast spinup list\n",
    "    M_forecasts = 100\n",
    "    S_forecast_steps = 500\n",
    "    max_spinup  = len(test_data) - S_forecast_steps\n",
    "    spinup_list = np.zeros(M_forecasts, dtype=np.uint32)\n",
    "    for i in range(M_forecasts):\n",
    "        spinup_list[i] = round(max_spinup * np.random.rand())    \n",
    "    \n",
    "    for i in range(len_vec):\n",
    "        # Setting random seed for repeteability\n",
    "        np.random.seed(rnd_seed)\n",
    "        random.seed(rnd_seed)\n",
    "        # set hyperparameter from cartesian product\n",
    "        D      = 3\n",
    "        N      = cart_prod[i][0]\n",
    "        rhoSR  = cart_prod[i][1]\n",
    "        rhoA   = cart_prod[i][2]\n",
    "        alpha  = cart_prod[i][3]  \n",
    "        sigma  = cart_prod[i][4]\n",
    "        sigmab = cart_prod[i][5] \n",
    "        beta   = cart_prod[i][6]\n",
    "        #\n",
    "        model   = ReservoirComputer(D, N, rhoSR, rhoA, alpha, sigma, sigmab, beta)\n",
    "        # training\n",
    "        washout = 100 # transitory skipped timesteps\n",
    "        model.train(training_data, washout)\n",
    "        # compute loss macro value\n",
    "        vec_loss_macro[i] = loss_macro(model,test_data,spinup_list,S_forecast_steps)\n",
    "        #print(\"i =\",i, vec_loss_macro[i])\n",
    "        \n",
    "        del model\n",
    "        \n",
    "    idx_vec_loss_macro = np.argmin(vec_loss_macro, axis=-1)\n",
    "    print(\"      ===== best hyperparameters\")\n",
    "    print(\"            N       \",cart_prod[idx_vec_loss_macro][0])\n",
    "    print(\"            rhoSR   \",cart_prod[idx_vec_loss_macro][1])\n",
    "    print(\"            rhoA    \",cart_prod[idx_vec_loss_macro][2])\n",
    "    print(\"            alpha   \",cart_prod[idx_vec_loss_macro][3])\n",
    "    print(\"            sigma   \",cart_prod[idx_vec_loss_macro][4])\n",
    "    print(\"            sigmab  \",cart_prod[idx_vec_loss_macro][5])\n",
    "    print(\"            beta    \",cart_prod[idx_vec_loss_macro][6])\n",
    "    print(\"            loss    \",vec_loss_macro[idx_vec_loss_macro])\n",
    "\n",
    "    # store best hyperparameters\n",
    "    cnt += 1\n",
    "    RC_HP[cnt][0]  = rho_Lorenz\n",
    "    RC_HP[cnt][1]  = D\n",
    "    RC_HP[cnt][2]  = washout\n",
    "    RC_HP[cnt][3]  = cart_prod[idx_vec_loss_macro][0]\n",
    "    RC_HP[cnt][4]  = cart_prod[idx_vec_loss_macro][1]\n",
    "    RC_HP[cnt][5]  = cart_prod[idx_vec_loss_macro][2]\n",
    "    RC_HP[cnt][6]  = cart_prod[idx_vec_loss_macro][3]\n",
    "    RC_HP[cnt][7]  = cart_prod[idx_vec_loss_macro][4]\n",
    "    RC_HP[cnt][8]  = cart_prod[idx_vec_loss_macro][5]\n",
    "    RC_HP[cnt][9]  = cart_prod[idx_vec_loss_macro][6]\n",
    "    RC_HP[cnt][10] = vec_loss_macro[idx_vec_loss_macro]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26b060c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy array to pandas DataFrame\n",
    "df_RC_HP = pd.DataFrame(RC_HP)\n",
    "\n",
    "# Name columns\n",
    "df_RC_HP.columns =['rho_Lorenz',\n",
    "                   'D',\n",
    "                   'washout',\n",
    "                   'N',        \n",
    "                   'rhoSR',   \n",
    "                   'rhoA',    \n",
    "                   'alpha',    \n",
    "                   'sigma',    \n",
    "                   'sigmab',   \n",
    "                   'beta',\n",
    "                   'loss']\n",
    "\n",
    "# Save DataFrame to .csv\n",
    "df_RC_HP.to_csv('climate/'+ nome_file + '.csv', index=False, header=True, decimal='.', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60fe6ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 2.76e+04 s\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------#---------------------------------------------------------------------#\n",
    "# Elapsed time\n",
    "#---------------------------------------------------------------------#\n",
    "print(f'\\nElapsed time {time.time() - start_time:6.2e} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1fadde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
