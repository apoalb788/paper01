{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "556b81cf",
   "metadata": {},
   "source": [
    "# Standard Reservoir Computer (paper version)\n",
    "\n",
    "### hyperparameters optimization\n",
    "\n",
    "### ( datasets by $\\rho \\in A =$ list of values  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae665baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import math     as math\n",
    "import numpy    as np\n",
    "import networkx as nx\n",
    "import random   as random\n",
    "import pandas   as pd\n",
    "import time     as time\n",
    "\n",
    "#######################################################################\n",
    "# E N V I R O N M E N T   S E T   U P\n",
    "#######################################################################\n",
    "#---------------------------------------------------------------------#\n",
    "# To compute elapsed time\n",
    "#---------------------------------------------------------------------#\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5bb9f7",
   "metadata": {},
   "source": [
    "## variables description\n",
    "    D       :(int  ) Input data dimension      \n",
    "    N       :(int  ) Reservoir dimension (degrees of freedome of the reservoir)       \n",
    "    rhoSR   :(float) Spectral Radius of A      \n",
    "    rhoA    :(float) Density of A              \n",
    "    alpha   :(float) Leak (or leakage) rate in (0,1]                 \n",
    "    sigma   :(float) Strength of input signal            \n",
    "    sigmab  :(float) Strength of input bias               \n",
    "    beta    :(float) Tichonov-Miller regularization parameter\n",
    "    \n",
    "    washout :(int)   During training, skipped transitory timesteps in W_out calculation\n",
    "    spinup  :(int)   Time (n. of timesteps) it takes for a trained RC to converge from its initial condition\n",
    "                     onto the synchronization manifold to which it is driven by the input data\n",
    "    normtime:(int)   Range to skip some QR factorisations and speed up the calculations  \n",
    "            \n",
    "    r       :(float) Reservoir state\n",
    "    W_in    :(float) Input matrix              \n",
    "    A       :(float) Reservoir ajacency matrix \n",
    "    b       :(float) bias vector               \n",
    "    W_out   :(float) Output matrix  \n",
    "    endtr_r :(float) Last reservoir state in training\n",
    "    \n",
    "    R       :(float) Matrix containing r(t) for all t in training dataset\n",
    "    U       :(float) Matrix containing u(t) for all t in training dataset\n",
    "    u       :(float) Time series at time t\n",
    "    v       :(float) Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129942da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReservoirComputer class declaration\n",
    "class ReservoirComputer:\n",
    "    def __init__(self, D, N, rhoSR, rhoA, alpha, sigma, sigmab, beta):\n",
    "        self.r      = np.zeros(N)\n",
    "        self.W_in   = get_random_matrix(N, D, xa=-sigma, xb=sigma, nonzero=False)\n",
    "        self.A      = generate_adjacency_matrix(N, rhoSR, rhoA)\n",
    "        self.b      = sigmab * np.ones(N)\n",
    "        self.W_out  = np.zeros((D,N))\n",
    "        self.endtr_r= np.zeros(N)\n",
    "\n",
    "    def rc_update_rule(self, y):\n",
    "        # driven     mode: y = u(t)         ;r(t+1) = F^d_r (r(t),y)\n",
    "        # autonomous mode: y = W_out . r(t) ;r(t+1) = F^a_r (r(t),y)\n",
    "        g      = np.dot(self.A, self.r) + np.dot(self.W_in, y) + self.b\n",
    "        self.r = alpha * np.tanh(g) + (1 - alpha) * self.r\n",
    "\n",
    "    def update_v(self):\n",
    "        return np.dot(self.W_out, self.r)\n",
    "\n",
    "    def train(self, U, washout):\n",
    "        steps = U.shape[0]\n",
    "        R     = np.zeros((N, steps))\n",
    "        for i in range(steps):\n",
    "            R[:, i] = self.r\n",
    "            u       = U[i]\n",
    "            self.rc_update_rule(u)\n",
    "        self.W_out = linear_regression(R[:,washout:], U[washout:], beta)\n",
    "        self.endtr_r = self.r # save last training r state\n",
    "\n",
    "    def spinup(self, U, steps):\n",
    "        self.r = self.endtr_r # reset reservoir state\n",
    "        if steps > 0:\n",
    "            for i in range(steps):\n",
    "                u = U[i]\n",
    "                self.rc_update_rule(u) # driven mode\n",
    "    \n",
    "    def predict(self, steps):\n",
    "        prediction = np.zeros((steps, D))\n",
    "        for i in range(steps):\n",
    "            v             = self.update_v()\n",
    "            prediction[i] = v\n",
    "            self.rc_update_rule(v)\n",
    "        return prediction\n",
    "\n",
    "    def rc_lyapunov_exponents(self, steps, dt, normtime):\n",
    "        save_r = self.r # save r state\n",
    "        self.r = self.endtr_r # reset r state\n",
    "        lyap   = np.zeros((N,steps))\n",
    "        M      = np.eye(N)\n",
    "        W      = self.A + np.dot(self.W_in,self.W_out)\n",
    "        j      = -1\n",
    "        for i in range(steps):\n",
    "            v     = self.update_v()\n",
    "            self.rc_update_rule(v) # update r\n",
    "            #\n",
    "            g     = np.dot(W, self.r) + self.b\n",
    "            DF    = alpha * np.dot(np.diag(1 - np.tanh(g)**2),W) \\\n",
    "                    + (1 - alpha) * np.eye(N)\n",
    "            Mn    = np.dot(DF,M)\n",
    "            if (i % normtime == 0):\n",
    "                Q,Rii = np.linalg.qr(Mn)\n",
    "                j     += 1\n",
    "                lyap[:,j] = np.log(abs(np.diag(Rii)))\n",
    "                M = Q\n",
    "        L = np.sum(lyap,1) / ((j+1)*dt)    \n",
    "        self.r = save_r # retrieve saved r_state\n",
    "        return L\n",
    "\n",
    "    def rc_conditional_lyapunov_exponents(self, U, dt, normtime):\n",
    "        save_r = self.r # save r state\n",
    "        self.r = np.zeros(N) # reset r state\n",
    "        steps  = U.shape[0]\n",
    "        lyap   = np.zeros((N,steps))\n",
    "        M      = np.eye(N)\n",
    "        j      = -1\n",
    "        for i in range(steps):\n",
    "            u       = U[i]\n",
    "            self.rc_update_rule(u) # update r\n",
    "            #\n",
    "            g  = np.dot(self.A, self.r) + np.dot(self.W_in, u) + self.b\n",
    "            DF = alpha * np.dot(np.diag(1 - np.tanh(g)**2),self.A) \\\n",
    "                 + (1 - alpha) * np.eye(N)\n",
    "            Mn = np.dot(DF,M)\n",
    "            if (i % normtime == 0):\n",
    "                Q,Rii = np.linalg.qr(Mn)\n",
    "                j     += 1\n",
    "                lyap[:,j] = np.log(abs(np.diag(Rii)))\n",
    "                M = Q\n",
    "        CL = np.sum(lyap,1) / ((j+1)*dt)\n",
    "        self.r = save_r # retrieve saved r_state\n",
    "        return CL\n",
    "    \n",
    "# Helper functions\n",
    "def generate_adjacency_matrix(N, rhoSR, rhoA):\n",
    "    # Erdos-Reyni network\n",
    "    graph = nx.gnp_random_graph(N, rhoA)\n",
    "    adj   = nx.to_numpy_array(graph)\n",
    "    # Ensure random_array is of the same shape as the graph adjacency matrix\n",
    "    random_array = get_random_matrix(N, N, xa =-0.5, xb=0.5, nonzero=True)\n",
    "    # Multiply graph adjacency matrix with random values\n",
    "    rescaled     = adj * random_array\n",
    "    return scale_matrix(rescaled, rhoSR)\n",
    "\n",
    "def get_random_matrix(nrow, ncol, xa, xb, nonzero):\n",
    "    B = np.zeros((nrow,ncol))\n",
    "    for i in range(nrow):\n",
    "        for j in range(ncol):\n",
    "            if nonzero:\n",
    "                while B[i,j] == 0:\n",
    "                    B[i,j] = xa + (xb - xa) * np.random.rand()\n",
    "            else:\n",
    "                B[i,j] = xa + (xb - xa) * np.random.rand()\n",
    "    return B\n",
    "\n",
    "def scale_matrix(A, rhoSR):\n",
    "    eigenvalues = np.linalg.eigvals(A)    # compute eigenvlaues\n",
    "    sr = np.max(np.absolute(eigenvalues)) # compute spectral radius of A\n",
    "    if sr > 0:\n",
    "        A = A * rhoSR / sr                # rescaling matrix if A non zero\n",
    "    return A\n",
    "\n",
    "def linear_regression(R, U, beta=.0001): \n",
    "    Rt = np.transpose(R)\n",
    "    inverse_part = np.linalg.inv(np.dot(R, Rt) + beta * np.identity(R.shape[0]))\n",
    "    return np.dot(np.dot(U.T, Rt), inverse_part)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f1b2277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# O P T I M I Z A T I O N   L O S S   F U N C T I O N \n",
    "#######################################################################\n",
    "# spinup_list = list of spinups values for forecasting \n",
    "def loss_macro(RC,test_data,spinup_list,forecast_steps):\n",
    "    loss_value = 0.\n",
    "    for i in range(len(spinup_list)):\n",
    "        spinup_steps = spinup_list[i]\n",
    "        RC.spinup(test_data, spinup_steps)\n",
    "        #\n",
    "        pred_data = RC.predict(forecast_steps)\n",
    "        #\n",
    "        for j in range(forecast_steps):\n",
    "            loss_value += np.linalg.norm(test_data[spinup_steps+j] - pred_data[j])**2 \\\n",
    "                        * np.exp(- (j+1) / (forecast_steps) )\n",
    "    return loss_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42a8094c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HP list length = 36\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "# H Y P E R P A R A M E T E R S   L I S T \n",
    "#######################################################################\n",
    "N_list      = [400]\n",
    "rhoSR_list  = [0.2, 0.5, 0.8]\n",
    "rhoA_list   = [0.02]\n",
    "alpha_list  = [0.4, 0.6, 0.8]\n",
    "sigma_list  = [0.084]\n",
    "sigmab_list = [1.1, 1.3, 1.5, 1.7]\n",
    "beta_list   = [8.5e-8]\n",
    "\n",
    "cart_prod = [(a,b,c,d,e,f,g)\n",
    "             for a in N_list       \n",
    "             for b in rhoSR_list   \n",
    "             for c in rhoA_list    \n",
    "             for d in alpha_list   \n",
    "             for e in sigma_list   \n",
    "             for f in sigmab_list  \n",
    "             for g in beta_list   ]\n",
    "\n",
    "len_vec = len(cart_prod)\n",
    "vec_loss_macro = np.zeros(len_vec)\n",
    "\n",
    "print(\"HP list length =\",len_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae59a5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "# L I S T   O F   R H O   V A L U E S\n",
    "#######################################################################\n",
    "rho_list  = np.arange(166, 167.01, .01)\n",
    "rho_list  = np.round(rho_list,2)\n",
    "\n",
    "rho_list  = np.sort(rho_list)\n",
    "\n",
    "len_rho_list = len(rho_list)\n",
    "\n",
    "print(len_rho_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33351fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166.0\n",
      "166.01\n",
      "166.02\n",
      "166.03\n",
      "166.04\n",
      "166.05\n",
      "166.06\n",
      "166.07\n",
      "166.08\n",
      "166.09\n",
      "166.1\n",
      "166.11\n",
      "166.12\n",
      "166.13\n",
      "166.14\n",
      "166.15\n",
      "166.16\n",
      "166.17\n",
      "166.18\n",
      "166.19\n",
      "166.2\n",
      "166.21\n",
      "166.22\n",
      "166.23\n",
      "166.24\n",
      "166.25\n",
      "166.26\n",
      "166.27\n",
      "166.28\n",
      "166.29\n",
      "166.3\n",
      "166.31\n",
      "166.32\n",
      "166.33\n",
      "166.34\n",
      "166.35\n",
      "166.36\n",
      "166.37\n",
      "166.38\n",
      "166.39\n",
      "166.4\n",
      "166.41\n",
      "166.42\n",
      "166.43\n",
      "166.44\n",
      "166.45\n",
      "166.46\n",
      "166.47\n",
      "166.48\n",
      "166.49\n",
      "166.5\n",
      "166.51\n",
      "166.52\n",
      "166.53\n",
      "166.54\n",
      "166.55\n",
      "166.56\n",
      "166.57\n",
      "166.58\n",
      "166.59\n",
      "166.6\n",
      "166.61\n",
      "166.62\n",
      "166.63\n",
      "166.64\n",
      "166.65\n",
      "166.66\n",
      "166.67\n",
      "166.68\n",
      "166.69\n",
      "166.7\n",
      "166.71\n",
      "166.72\n",
      "166.73\n",
      "166.74\n",
      "166.75\n",
      "166.76\n",
      "166.77\n",
      "166.78\n",
      "166.79\n",
      "166.8\n",
      "166.81\n",
      "166.82\n",
      "166.83\n",
      "166.84\n",
      "166.85\n",
      "166.86\n",
      "166.87\n",
      "166.88\n",
      "166.89\n",
      "166.9\n",
      "166.91\n",
      "166.92\n",
      "166.93\n",
      "166.94\n",
      "166.95\n",
      "166.96\n",
      "166.97\n",
      "166.98\n",
      "166.99\n",
      "167.0\n"
     ]
    }
   ],
   "source": [
    "for s in range(len_rho_list):\n",
    "    print(rho_list[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b113a7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====     0) : Lorenz rho = 166.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     189620.14311385842\n",
      "=====     1) : Lorenz rho = 166.010\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     22123.43931248905\n",
      "=====     2) : Lorenz rho = 166.020\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     16996.16285001758\n",
      "=====     3) : Lorenz rho = 166.030\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     304488.30970503436\n",
      "=====     4) : Lorenz rho = 166.040\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     189093.57140629255\n",
      "=====     5) : Lorenz rho = 166.050\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.5\n",
      "            beta     8.5e-08\n",
      "            loss     9001.01555974096\n",
      "=====     6) : Lorenz rho = 166.060\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     13920.79578398414\n",
      "=====     7) : Lorenz rho = 166.070\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     101752396.55083239\n",
      "=====     8) : Lorenz rho = 166.080\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     13165536.894687053\n",
      "=====     9) : Lorenz rho = 166.090\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     389134939.7637738\n",
      "=====    10) : Lorenz rho = 166.100\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     128412082.33077067\n",
      "=====    11) : Lorenz rho = 166.110\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     173604539.3910505\n",
      "=====    12) : Lorenz rho = 166.120\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     236478623.5641114\n",
      "=====    13) : Lorenz rho = 166.130\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     20955935.537079506\n",
      "=====    14) : Lorenz rho = 166.140\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     754631478.8006337\n",
      "=====    15) : Lorenz rho = 166.150\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     286348370.71469194\n",
      "=====    16) : Lorenz rho = 166.160\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     152297618.4214402\n",
      "=====    17) : Lorenz rho = 166.170\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     315482025.0572889\n",
      "=====    18) : Lorenz rho = 166.180\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     248429483.41340205\n",
      "=====    19) : Lorenz rho = 166.190\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     408180344.5392262\n",
      "=====    20) : Lorenz rho = 166.200\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     412358275.8234303\n",
      "=====    21) : Lorenz rho = 166.210\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.5\n",
      "            beta     8.5e-08\n",
      "            loss     456358680.5286064\n",
      "=====    22) : Lorenz rho = 166.220\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     213983542.66265434\n",
      "=====    23) : Lorenz rho = 166.230\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     384351235.47007\n",
      "=====    24) : Lorenz rho = 166.240\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     337305069.44691825\n",
      "=====    25) : Lorenz rho = 166.250\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     148761547.1390013\n",
      "=====    26) : Lorenz rho = 166.260\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     203213161.22178066\n",
      "=====    27) : Lorenz rho = 166.270\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.5\n",
      "            beta     8.5e-08\n",
      "            loss     697653858.8594309\n",
      "=====    28) : Lorenz rho = 166.280\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     133368821.78998043\n",
      "=====    29) : Lorenz rho = 166.290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     265004912.5219084\n",
      "=====    30) : Lorenz rho = 166.300\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.8\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     97860614.21973775\n",
      "=====    31) : Lorenz rho = 166.310\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     807269372.4250444\n",
      "=====    32) : Lorenz rho = 166.320\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     569256067.4682728\n",
      "=====    33) : Lorenz rho = 166.330\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     752532138.4905454\n",
      "=====    34) : Lorenz rho = 166.340\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     1056055525.5981947\n",
      "=====    35) : Lorenz rho = 166.350\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     275025112.10546845\n",
      "=====    36) : Lorenz rho = 166.360\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     826097719.4659362\n",
      "=====    37) : Lorenz rho = 166.370\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     214343570.09566933\n",
      "=====    38) : Lorenz rho = 166.380\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     540798875.6432773\n",
      "=====    39) : Lorenz rho = 166.390\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     423555871.8600698\n",
      "=====    40) : Lorenz rho = 166.400\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     214233010.85744315\n",
      "=====    41) : Lorenz rho = 166.410\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     584273867.8236101\n",
      "=====    42) : Lorenz rho = 166.420\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     607398125.9375252\n",
      "=====    43) : Lorenz rho = 166.430\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     125671402.3164539\n",
      "=====    44) : Lorenz rho = 166.440\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     1344857381.3684578\n",
      "=====    45) : Lorenz rho = 166.450\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     1044389519.6327449\n",
      "=====    46) : Lorenz rho = 166.460\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     679185779.4854373\n",
      "=====    47) : Lorenz rho = 166.470\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     611248107.0586638\n",
      "=====    48) : Lorenz rho = 166.480\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     67974582.00061908\n",
      "=====    49) : Lorenz rho = 166.490\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     489829970.8707698\n",
      "=====    50) : Lorenz rho = 166.500\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     1108066743.340844\n",
      "=====    51) : Lorenz rho = 166.510\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     1331286786.7689488\n",
      "=====    52) : Lorenz rho = 166.520\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.8\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     178092970.2724741\n",
      "=====    53) : Lorenz rho = 166.530\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     148565831.9872182\n",
      "=====    54) : Lorenz rho = 166.540\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     291196910.16631866\n",
      "=====    55) : Lorenz rho = 166.550\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     652822865.5419554\n",
      "=====    56) : Lorenz rho = 166.560\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     1292534803.3289444\n",
      "=====    57) : Lorenz rho = 166.570\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     626421228.5350713\n",
      "=====    58) : Lorenz rho = 166.580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.8\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     1304423345.6555893\n",
      "=====    59) : Lorenz rho = 166.590\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     2244437930.2899003\n",
      "=====    60) : Lorenz rho = 166.600\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     419485721.32468265\n",
      "=====    61) : Lorenz rho = 166.610\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     645668618.1673906\n",
      "=====    62) : Lorenz rho = 166.620\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     271368418.9629357\n",
      "=====    63) : Lorenz rho = 166.630\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     495261567.6416443\n",
      "=====    64) : Lorenz rho = 166.640\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     583564044.5683115\n",
      "=====    65) : Lorenz rho = 166.650\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     1933469983.7517622\n",
      "=====    66) : Lorenz rho = 166.660\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     146242245.45433512\n",
      "=====    67) : Lorenz rho = 166.670\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     835774949.970027\n",
      "=====    68) : Lorenz rho = 166.680\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     1051709918.1354711\n",
      "=====    69) : Lorenz rho = 166.690\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     225608733.1386883\n",
      "=====    70) : Lorenz rho = 166.700\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     821956398.2843453\n",
      "=====    71) : Lorenz rho = 166.710\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     407372790.7375907\n",
      "=====    72) : Lorenz rho = 166.720\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     1649734074.3840213\n",
      "=====    73) : Lorenz rho = 166.730\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     115072935.5575507\n",
      "=====    74) : Lorenz rho = 166.740\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     351256322.0954033\n",
      "=====    75) : Lorenz rho = 166.750\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     517209990.1045973\n",
      "=====    76) : Lorenz rho = 166.760\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     1089792858.531961\n",
      "=====    77) : Lorenz rho = 166.770\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     1072968245.0670488\n",
      "=====    78) : Lorenz rho = 166.780\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     994027296.150849\n",
      "=====    79) : Lorenz rho = 166.790\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     1277595670.206854\n",
      "=====    80) : Lorenz rho = 166.800\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     1030836466.9950444\n",
      "=====    81) : Lorenz rho = 166.810\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     184957444.112752\n",
      "=====    82) : Lorenz rho = 166.820\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.5\n",
      "            beta     8.5e-08\n",
      "            loss     569963668.0409288\n",
      "=====    83) : Lorenz rho = 166.830\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     610848764.4284416\n",
      "=====    84) : Lorenz rho = 166.840\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     122360860.0022889\n",
      "=====    85) : Lorenz rho = 166.850\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     751608578.713666\n",
      "=====    86) : Lorenz rho = 166.860\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.6\n",
      "            sigma    0.084\n",
      "            sigmab   1.5\n",
      "            beta     8.5e-08\n",
      "            loss     676343046.2685492\n",
      "=====    87) : Lorenz rho = 166.870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     1470733995.101508\n",
      "=====    88) : Lorenz rho = 166.880\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     269269496.76449895\n",
      "=====    89) : Lorenz rho = 166.890\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.5\n",
      "            beta     8.5e-08\n",
      "            loss     688495115.7817172\n",
      "=====    90) : Lorenz rho = 166.900\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     728870399.0925199\n",
      "=====    91) : Lorenz rho = 166.910\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     540073456.0451766\n",
      "=====    92) : Lorenz rho = 166.920\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     440876927.3622371\n",
      "=====    93) : Lorenz rho = 166.930\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.8\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     867543865.3820503\n",
      "=====    94) : Lorenz rho = 166.940\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     1196007441.9238436\n",
      "=====    95) : Lorenz rho = 166.950\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     430954361.7593476\n",
      "=====    96) : Lorenz rho = 166.960\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     333828775.6341464\n",
      "=====    97) : Lorenz rho = 166.970\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     1459511819.5105634\n",
      "=====    98) : Lorenz rho = 166.980\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.3\n",
      "            beta     8.5e-08\n",
      "            loss     1167061514.0461268\n",
      "=====    99) : Lorenz rho = 166.990\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.2\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.7\n",
      "            beta     8.5e-08\n",
      "            loss     964776918.8171458\n",
      "=====   100) : Lorenz rho = 167.000\n",
      "      ===== best hyperparameters\n",
      "            N        400\n",
      "            rhoSR    0.5\n",
      "            rhoA     0.02\n",
      "            alpha    0.4\n",
      "            sigma    0.084\n",
      "            sigmab   1.1\n",
      "            beta     8.5e-08\n",
      "            loss     729360192.3184005\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "# O P T I M I Z A T I O N   L O O P \n",
    "#######################################################################\n",
    "rnd_seed = 167\n",
    "nome_file = 'df_RC400_seed' + str(rnd_seed) + '_HP_intermittency'\n",
    "s_from = 0\n",
    "s_to   = 101\n",
    "# store parameters and RC hyperparameters\n",
    "RC_HP   = np.zeros((s_to - s_from, 11)) #np.zeros((len_rho_list, 11))\n",
    "\n",
    "cnt = -1\n",
    "for s in range(s_from, s_to): #range(len_rho_list):\n",
    "    rho_Lorenz  = rho_list[s]\n",
    "    # read dataset\n",
    "    str_rho_Lorenz = (f'{rho_Lorenz:07.3f}').replace(\".\", \"_\")\n",
    "    print(\"===== \",f'{s:>4d}) : Lorenz rho = {rho_Lorenz:>7.3f}')\n",
    "    X = np.loadtxt('dataset2/Lorenz_Dataset_'+str(str_rho_Lorenz)+'.csv',delimiter=\";\")\n",
    "    n_timesteps = len(X)\n",
    "    #print(n_timesteps)\n",
    "    \n",
    "    # splitting in training and test dataset\n",
    "    data_length          = len(X) \n",
    "    training_percentage  = .8\n",
    "    training_data_length = round(training_percentage * data_length) \n",
    "    #print(\"data_length          =\",data_length)\n",
    "    #print(\"training_data_length =\",training_data_length)\n",
    "    training_data = np.array(X[:training_data_length])\n",
    "    test_data     = np.array(X[training_data_length:])\n",
    "    \n",
    "    # Setting random seed for repeteability\n",
    "    np.random.seed(rnd_seed)\n",
    "    random.seed(rnd_seed)\n",
    "    \n",
    "    # Set random forecast spinup list\n",
    "    M_forecasts = 100\n",
    "    S_forecast_steps = 500\n",
    "    max_spinup  = len(test_data) - S_forecast_steps\n",
    "    spinup_list = np.zeros(M_forecasts, dtype=np.uint32)\n",
    "    for i in range(M_forecasts):\n",
    "        spinup_list[i] = round(max_spinup * np.random.rand())    \n",
    "    \n",
    "    for i in range(len_vec):\n",
    "        # Setting random seed for repeteability\n",
    "        np.random.seed(rnd_seed)\n",
    "        random.seed(rnd_seed)\n",
    "        # set hyperparameter from cartesian product\n",
    "        D      = 3\n",
    "        N      = cart_prod[i][0]\n",
    "        rhoSR  = cart_prod[i][1]\n",
    "        rhoA   = cart_prod[i][2]\n",
    "        alpha  = cart_prod[i][3]  \n",
    "        sigma  = cart_prod[i][4]\n",
    "        sigmab = cart_prod[i][5] \n",
    "        beta   = cart_prod[i][6]\n",
    "        #\n",
    "        model   = ReservoirComputer(D, N, rhoSR, rhoA, alpha, sigma, sigmab, beta)\n",
    "        # training\n",
    "        washout = 100 # transitory skipped timesteps\n",
    "        model.train(training_data, washout)\n",
    "        # compute loss macro value\n",
    "        vec_loss_macro[i] = loss_macro(model,test_data,spinup_list,S_forecast_steps)\n",
    "        #print(\"i =\",i, vec_loss_macro[i])\n",
    "        \n",
    "        del model\n",
    "        \n",
    "    idx_vec_loss_macro = np.argmin(vec_loss_macro, axis=-1)\n",
    "    print(\"      ===== best hyperparameters\")\n",
    "    print(\"            N       \",cart_prod[idx_vec_loss_macro][0])\n",
    "    print(\"            rhoSR   \",cart_prod[idx_vec_loss_macro][1])\n",
    "    print(\"            rhoA    \",cart_prod[idx_vec_loss_macro][2])\n",
    "    print(\"            alpha   \",cart_prod[idx_vec_loss_macro][3])\n",
    "    print(\"            sigma   \",cart_prod[idx_vec_loss_macro][4])\n",
    "    print(\"            sigmab  \",cart_prod[idx_vec_loss_macro][5])\n",
    "    print(\"            beta    \",cart_prod[idx_vec_loss_macro][6])\n",
    "    print(\"            loss    \",vec_loss_macro[idx_vec_loss_macro])\n",
    "\n",
    "    # store best hyperparameters\n",
    "    cnt += 1\n",
    "    RC_HP[cnt][0]  = rho_Lorenz\n",
    "    RC_HP[cnt][1]  = D\n",
    "    RC_HP[cnt][2]  = washout\n",
    "    RC_HP[cnt][3]  = cart_prod[idx_vec_loss_macro][0]\n",
    "    RC_HP[cnt][4]  = cart_prod[idx_vec_loss_macro][1]\n",
    "    RC_HP[cnt][5]  = cart_prod[idx_vec_loss_macro][2]\n",
    "    RC_HP[cnt][6]  = cart_prod[idx_vec_loss_macro][3]\n",
    "    RC_HP[cnt][7]  = cart_prod[idx_vec_loss_macro][4]\n",
    "    RC_HP[cnt][8]  = cart_prod[idx_vec_loss_macro][5]\n",
    "    RC_HP[cnt][9]  = cart_prod[idx_vec_loss_macro][6]\n",
    "    RC_HP[cnt][10] = vec_loss_macro[idx_vec_loss_macro]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26b060c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy array to pandas DataFrame\n",
    "df_RC_HP = pd.DataFrame(RC_HP)\n",
    "\n",
    "# Name columns\n",
    "df_RC_HP.columns =['rho_Lorenz',\n",
    "                   'D',\n",
    "                   'washout',\n",
    "                   'N',        \n",
    "                   'rhoSR',   \n",
    "                   'rhoA',    \n",
    "                   'alpha',    \n",
    "                   'sigma',    \n",
    "                   'sigmab',   \n",
    "                   'beta',\n",
    "                   'loss']\n",
    "\n",
    "# Save DataFrame to .csv\n",
    "df_RC_HP.to_csv('climate/'+ nome_file + '.csv', index=False, header=True, decimal='.', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60fe6ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 5.03e+04 s\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------#---------------------------------------------------------------------#\n",
    "# Elapsed time\n",
    "#---------------------------------------------------------------------#\n",
    "print(f'\\nElapsed time {time.time() - start_time:6.2e} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1fadde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
